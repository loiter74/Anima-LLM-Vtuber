# Anima åç«¯ API æ–‡æ¡£

## ç›®å½•

1. [æ¦‚è¿°](#1-æ¦‚è¿°)
2. [Socket.IO äº‹ä»¶](#2-socket-io-äº‹ä»¶)
3. [æœåŠ¡é…ç½®](#3-æœåŠ¡é…ç½®)
4. [Persona ç³»ç»Ÿ](#4-persona-ç³»ç»Ÿ)
5. [æ•°æ®ç»“æ„](#5-æ•°æ®ç»“æ„)
6. [éŸ³é¢‘å¤„ç†è§„èŒƒ](#6-éŸ³é¢‘å¤„ç†è§„èŒƒ)
7. [ä¼šè¯ç®¡ç†](#7-ä¼šè¯ç®¡ç†)
8. [ç¯å¢ƒå˜é‡](#8-ç¯å¢ƒå˜é‡)
9. [å¸¸é‡å’Œæšä¸¾](#9-å¸¸é‡å’Œæšä¸¾)
10. [CORS å’Œå®‰å…¨](#10-cors-å’Œå®‰å…¨)
11. [ç¤ºä¾‹ä»£ç ](#11-ç¤ºä¾‹ä»£ç )
12. [æ•…éšœæ’æŸ¥](#12-æ•…éšœæ’æŸ¥)

---

## 1. æ¦‚è¿°

### 1.1 æ¶æ„ç®€ä»‹

Anima é‡‡ç”¨ **Pipeline + EventBus** æ¨¡å¼çš„æ¨¡å—åŒ–æ¶æ„ï¼š

```
WebSocket Server -> ConversationOrchestrator -> Pipeline System -> EventBus -> Handlers
                      â†“
                ServiceContext (ASR/TTS/LLM/VAD)
```

**æ ¸å¿ƒç»„ä»¶ï¼š**
- **Socket.IO Server** - å¤„ç† WebSocket è¿æ¥å’Œäº‹ä»¶
- **ConversationOrchestrator** - å¯¹è¯ç¼–æ’å™¨ï¼Œæ•´åˆ ASRã€TTSã€LLM
- **InputPipeline** - å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆASR -> TextCleanï¼‰
- **OutputPipeline** - å¤„ç† AI å“åº”æµ
- **EventBus** - äº‹ä»¶å‘å¸ƒ/è®¢é˜…ç³»ç»Ÿ
- **ServiceContext** - æœåŠ¡å®¹å™¨ï¼ˆLLMã€ASRã€TTSã€VADï¼‰

### 1.2 é€šä¿¡åè®®

- **åè®®**: Socket.IO (WebSocket + Polling)
- **æœåŠ¡å™¨åœ°å€**: `http://localhost:12394`
- **ä¼ è¾“æ–¹å¼**: WebSocketï¼ˆé¦–é€‰ï¼‰ã€HTTP é•¿è½®è¯¢ï¼ˆå¤‡ç”¨ï¼‰

### 1.3 æœåŠ¡å™¨é…ç½®

é»˜è®¤æœåŠ¡å™¨é…ç½®ï¼ˆ`config/config.yaml`ï¼‰ï¼š

```yaml
system:
  host: "localhost"
  port: 12394
  debug: true
  log_level: "INFO"
```

### 1.4 CORS è®¾ç½®

å…è®¸çš„è·¨åŸŸæ¥æºï¼š

```python
allowed_origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "*"  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æ¥æº
]
```

---

## 2. Socket.IO äº‹ä»¶

### 2.1 å®¢æˆ·ç«¯ â†’ æœåŠ¡ç«¯äº‹ä»¶

#### äº‹ä»¶åˆ—è¡¨æ€»è§ˆ

| äº‹ä»¶å | æè¿° | æ•°æ®ç»“æ„ |
|--------|------|----------|
| `connect` | è¿æ¥å»ºç«‹ | - |
| `disconnect` | æ–­å¼€è¿æ¥ | - |
| `text_input` | æ–‡æœ¬è¾“å…¥ | `{text, metadata?, from_name?}` |
| `mic_audio_data` | éŸ³é¢‘æ•°æ®å—ï¼ˆç¼“å†²æ¨¡å¼ï¼‰ | `{audio: number[]}` |
| `raw_audio_data` | åŸå§‹éŸ³é¢‘æ•°æ®ï¼ˆVADæ¨¡å¼ï¼‰ | `{audio: number[]}` |
| `mic_audio_end` | éŸ³é¢‘è¾“å…¥ç»“æŸ | `{metadata?, from_name?}` |
| `interrupt_signal` | æ‰“æ–­å½“å‰å“åº” | `{text?}` |
| `fetch_history_list` | è·å–å†å²åˆ—è¡¨ | - |
| `fetch_history` | è·å–ç‰¹å®šå†å²è®°å½• | `{history_uid}` |
| `switch_config` | åˆ‡æ¢é…ç½® | `{file}` |
| `clear_history` | æ¸…ç©ºå¯¹è¯å†å² | - |
| `create_new_history` | åˆ›å»ºæ–°å¯¹è¯å†å² | - |
| `set_log_level` | è®¾ç½®æ—¥å¿—çº§åˆ« | `{level}` |
| `heartbeat` | å¿ƒè·³æ£€æµ‹ | - |

#### è¯¦ç»†äº‹ä»¶è¯´æ˜

##### `connect`

å®¢æˆ·ç«¯è¿æ¥æ—¶è‡ªåŠ¨è§¦å‘ï¼ˆæ— éœ€æ‰‹åŠ¨å‘é€ï¼‰ã€‚

**æœåŠ¡ç«¯å“åº”ï¼š**
- `connection-established` - è¿æ¥ç¡®è®¤

##### `text_input`

å‘é€æ–‡æœ¬æ¶ˆæ¯è¿›è¡Œå¤„ç†ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  text: string           // å¿…éœ€ï¼Œè¾“å…¥çš„æ–‡æœ¬å†…å®¹
  metadata?: object      // å¯é€‰ï¼Œå…ƒæ•°æ®
  from_name?: string     // å¯é€‰ï¼Œå‘é€è€…åç§°ï¼Œé»˜è®¤ "User"
}
```

**ç¤ºä¾‹ï¼š**
```typescript
socket.emit("text_input", {
  text: "ä½ å¥½ï¼ŒAnimaï¼",
  from_name: "User"
})
```

##### `mic_audio_data`

å‘é€éŸ³é¢‘æ•°æ®å—ï¼Œç”¨äºæ‰‹åŠ¨ç¼“å†²æ¨¡å¼ã€‚éœ€è¦é…åˆ `mic_audio_end` ä½¿ç”¨ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  audio: number[]        // float32 éŸ³é¢‘é‡‡æ ·ç‚¹æ•°ç»„
}
```

**éŸ³é¢‘è¦æ±‚ï¼š**
- é‡‡æ ·ç‡ï¼š16kHz
- æ ¼å¼ï¼šfloat32ï¼ŒèŒƒå›´ [-1.0, 1.0]
- å—å¤§å°ï¼šå»ºè®® 512-2048 é‡‡æ ·ç‚¹

##### `raw_audio_data`

å‘é€åŸå§‹éŸ³é¢‘æ•°æ®ï¼Œç”¨äº VAD è‡ªåŠ¨æ£€æµ‹æ¨¡å¼ã€‚VAD ä¼šè‡ªåŠ¨æ£€æµ‹è¯­éŸ³ç»“æŸå¹¶è§¦å‘å¤„ç†ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  audio: number[]        // int16 æˆ– float32 éŸ³é¢‘é‡‡æ ·ç‚¹æ•°ç»„
}
```

**VAD å¤„ç†æµç¨‹ï¼š**
1. æŒç»­å‘é€éŸ³é¢‘å—
2. VAD è‡ªåŠ¨æ£€æµ‹è¯­éŸ³å¼€å§‹/ç»“æŸ
3. è¯­éŸ³ç»“æŸåè‡ªåŠ¨è§¦å‘ ASR å’Œå¯¹è¯å¤„ç†
4. å‘é€ `mic-audio-end` æ§åˆ¶ä¿¡å·

##### `mic_audio_end`

æ‰‹åŠ¨è§¦å‘éŸ³é¢‘è¾“å…¥ç»“æŸï¼Œç”¨äº `mic_audio_data` ç¼“å†²æ¨¡å¼ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  metadata?: object      // å¯é€‰ï¼Œå…ƒæ•°æ®
  from_name?: string     // å¯é€‰ï¼Œå‘é€è€…åç§°
}
```

##### `interrupt_signal`

æ‰“æ–­å½“å‰æ­£åœ¨è¿›è¡Œçš„å¯¹è¯å’Œ TTS æ’­æ”¾ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  text?: string          // å¯é€‰ï¼Œç”¨æˆ·å¬åˆ°çš„éƒ¨åˆ†å›å¤
}
```

**æœåŠ¡ç«¯å“åº”ï¼š**
- `interrupted` - æ‰“æ–­ç¡®è®¤

##### `fetch_history_list`

è¯·æ±‚è·å–èŠå¤©å†å²åˆ—è¡¨ã€‚

**æœåŠ¡ç«¯å“åº”ï¼š**
- `history-list` - å†å²åˆ—è¡¨æ•°æ®

##### `fetch_history`

è¯·æ±‚è·å–ç‰¹å®šçš„å†å²è®°å½•ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  history_uid: string    // å†å²è®°å½•å”¯ä¸€ID
}
```

**æœåŠ¡ç«¯å“åº”ï¼š**
- `history-data` - å†å²æ¶ˆæ¯æ•°æ®

##### `switch_config`

åˆ‡æ¢é…ç½®æ–‡ä»¶ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  file: string           // é…ç½®æ–‡ä»¶å
}
```

**æœåŠ¡ç«¯å“åº”ï¼š**
- `config-switched` - åˆ‡æ¢ç¡®è®¤

##### `clear_history`

æ¸…ç©ºå½“å‰ä¼šè¯çš„å¯¹è¯å†å²ã€‚

**æœåŠ¡ç«¯å“åº”ï¼š**
- `history-cleared` - æ¸…ç©ºç¡®è®¤

##### `create_new_history`

åˆ›å»ºæ–°çš„å¯¹è¯å†å²ä¼šè¯ã€‚

**æœåŠ¡ç«¯å“åº”ï¼š**
- `new-history-created` - åˆ›å»ºç¡®è®¤

##### `set_log_level`

åŠ¨æ€è®¾ç½®åç«¯æ—¥å¿—çº§åˆ«ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  level: "TRACE" | "DEBUG" | "INFO" | "WARNING" | "ERROR" | "CRITICAL"
}
```

**æœåŠ¡ç«¯å“åº”ï¼š**
- `log_level_changed` - çº§åˆ«å˜æ›´ç¡®è®¤

**ç¤ºä¾‹ï¼š**
```typescript
socket.emit("set_log_level", { level: "DEBUG" })
```

##### `heartbeat`

å¿ƒè·³æ£€æµ‹ï¼Œç”¨äºä¿æŒè¿æ¥æ´»è·ƒã€‚

**æœåŠ¡ç«¯å“åº”ï¼š**
- `heartbeat-ack` - å¿ƒè·³ç¡®è®¤

---

### 2.2 æœåŠ¡ç«¯ â†’ å®¢æˆ·ç«¯äº‹ä»¶

#### äº‹ä»¶åˆ—è¡¨æ€»è§ˆ

| äº‹ä»¶å | æè¿° | æ•°æ®ç»“æ„ |
|--------|------|----------|
| `connection-established` | è¿æ¥å»ºç«‹ç¡®è®¤ | `{message, sid}` |
| `text` | æµå¼æ–‡æœ¬å“åº” | `{type, text, seq}` |
| `audio` | éŸ³é¢‘æ•°æ®å— | `{type, audio_data, format, seq}` |
| `transcript` | ç”¨æˆ·è¯­éŸ³è½¬å†™æ–‡æœ¬ | `{type, text}` |
| `control` | æ§åˆ¶ä¿¡å· | `{type, text}` |
| `error` | é”™è¯¯ä¿¡æ¯ | `{type, message}` |
| `heartbeat-ack` | å¿ƒè·³ç¡®è®¤ | - |
| `log_level_changed` | æ—¥å¿—çº§åˆ«å˜æ›´ | `{type, success, level, message}` |
| `history-list` | å†å²åˆ—è¡¨ | `{type, histories}` |
| `history-data` | å†å²æ¶ˆæ¯æ•°æ® | `{type, messages}` |
| `history-cleared` | å†å²æ¸…ç©ºç¡®è®¤ | `{type}` |
| `new-history-created` | æ–°å†å²åˆ›å»ºç¡®è®¤ | `{type, history_uid}` |
| `config-switched` | é…ç½®åˆ‡æ¢ç¡®è®¤ | `{type, message}` |

#### è¯¦ç»†äº‹ä»¶è¯´æ˜

##### `connection-established`

è¿æ¥æˆåŠŸæ—¶å‘é€ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  message: string        // æ¬¢è¿æ¶ˆæ¯
  sid: string           // ä¼šè¯ ID
}
```

##### `text` (åŸ `sentence`)

æµå¼æ–‡æœ¬å“åº”ï¼Œç”± AI ç”Ÿæˆçš„å†…å®¹åˆ†å—å‘é€ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "text"          // äº‹ä»¶ç±»å‹
  text: string          // æ–‡æœ¬å†…å®¹ï¼ˆç©ºå­—ç¬¦ä¸²è¡¨ç¤ºå“åº”ç»“æŸï¼‰
  seq: number           // åºåˆ—å·
}
```

**æ³¨æ„ï¼š** æ­¤äº‹ä»¶ç”± `SocketEventAdapter` ä» `sentence` äº‹ä»¶è½¬æ¢è€Œæ¥ã€‚

##### `audio`

TTS ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®å—ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "audio"         // äº‹ä»¶ç±»å‹
  audio_data: string    // Base64 ç¼–ç çš„éŸ³é¢‘æ•°æ®
  format: string        // éŸ³é¢‘æ ¼å¼ï¼ˆå¦‚ "wav", "mp3"ï¼‰
  seq: number           // åºåˆ—å·
}
```

##### `transcript` (åŸ `user-transcript`)

ç”¨æˆ·è¯­éŸ³è½¬å†™åçš„æ–‡æœ¬ï¼ˆASR ç»“æœï¼‰ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "transcript"    // äº‹ä»¶ç±»å‹
  text: string          // è½¬å†™åçš„æ–‡æœ¬
}
```

**æ³¨æ„ï¼š** æ­¤äº‹ä»¶ç”± `SocketEventAdapter` ä» `user-transcript` äº‹ä»¶è½¬æ¢è€Œæ¥ã€‚

##### `control`

æ§åˆ¶ä¿¡å·ï¼Œç”¨äºé€šçŸ¥å®¢æˆ·ç«¯çŠ¶æ€å˜åŒ–ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "control"       // äº‹ä»¶ç±»å‹
  text: string          // æ§åˆ¶ä¿¡å·åç§°
}
```

**å¯ç”¨çš„æ§åˆ¶ä¿¡å·ï¼š**
- `conversation-start` - å¯¹è¯å¼€å§‹ï¼Œå‰ç«¯åº”æš‚åœå‘é€éŸ³é¢‘
- `conversation-end` - å¯¹è¯ç»“æŸï¼Œå‰ç«¯å¯æ¢å¤å‘é€éŸ³é¢‘
- `asr-start` - ASR å¼€å§‹å¤„ç†
- `backend-synth-complete` - TTS åˆæˆå®Œæˆ
- `interrupt` - ä¸­æ–­ä¿¡å·
- `interrupted` - å·²è¢«ä¸­æ–­
- `start-mic` - å¯åŠ¨éº¦å…‹é£ç›‘å¬
- `stop-mic` - åœæ­¢éº¦å…‹é£ç›‘å¬
- `mic-audio-end` - VAD æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
- `no-audio-data` - æ— æœ‰æ•ˆéŸ³é¢‘æ•°æ®

##### `error`

é”™è¯¯ä¿¡æ¯äº‹ä»¶ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "error"         // äº‹ä»¶ç±»å‹
  message: string       // é”™è¯¯æ¶ˆæ¯
}
```

##### `log_level_changed`

æ—¥å¿—çº§åˆ«å˜æ›´ç¡®è®¤ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "log_level_changed"
  success: boolean      // æ˜¯å¦æˆåŠŸ
  level: string         // å½“å‰æ—¥å¿—çº§åˆ«
  message: string       // çŠ¶æ€æ¶ˆæ¯
}
```

##### `history-list`

å†å²è®°å½•åˆ—è¡¨ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "history-list"
  histories: Array<{
    uid: string         // å†å²è®°å½• ID
    preview: string     // é¢„è§ˆæ–‡æœ¬
  }>
}
```

##### `history-data`

å†å²æ¶ˆæ¯æ•°æ®ã€‚

**æ•°æ®ç»“æ„ï¼š**
```typescript
{
  type: "history-data"
  messages: Array<{
    role: string        // "user" æˆ– "assistant"
    content: string     // æ¶ˆæ¯å†…å®¹
  }>
}
```

---

### 2.3 äº‹ä»¶æµç¨‹å›¾

#### æ–‡æœ¬è¾“å…¥æµç¨‹

```
å®¢æˆ·ç«¯                    æœåŠ¡ç«¯
  |                         |
  |--- text_input --------->|
  |                         |-- ASR (è·³è¿‡)
  |                         |-- TextClean
  |                         |-- Agent.chat_stream()
  |<==== text (æµå¼) ========|
  |<==== audio (æµå¼) ========|
  |<-- conversation-end -----|
```

#### éŸ³é¢‘è¾“å…¥æµç¨‹ï¼ˆVAD æ¨¡å¼ï¼‰

```
å®¢æˆ·ç«¯                    æœåŠ¡ç«¯                      VAD
  |                         |                          |
  |--- raw_audio_data ------>|----- éŸ³é¢‘å— ------------>|
  |--- raw_audio_data ------>|----- éŸ³é¢‘å— ------------>|
  |--- raw_audio_data ------>|----- éŸ³é¢‘å— ------------>| è¯­éŸ³å¼€å§‹
  |<-- control (interrupt) --| (è‡ªåŠ¨æ‰“æ–­å½“å‰å›å¤)        |
  |--- raw_audio_data ------>|----- éŸ³é¢‘å— ------------>|
  |--- raw_audio_data ------>|----- éŸ³é¢‘å— ------------>| è¯­éŸ³ç»“æŸ
  |<-- mic-audio-end --------|                          |
  |                         |-- ASR è½¬å†™
  |<-- transcript ----------|--                       |
  |                         |-- Agent ç”Ÿæˆå“åº”
  |<==== text (æµå¼) =================================|
  |<==== audio (æµå¼) ================================|
  |<-- conversation-end -----|
```

#### éŸ³é¢‘è¾“å…¥æµç¨‹ï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼‰

```
å®¢æˆ·ç«¯                    æœåŠ¡ç«¯
  |                         |
  |--- mic_audio_data ------>| (ç¼“å†²éŸ³é¢‘)
  |--- mic_audio_data ------>| (ç¼“å†²éŸ³é¢‘)
  |--- mic_audio_data ------>| (ç¼“å†²éŸ³é¢‘)
  |--- mic_audio_end ------> |
  |                         |-- ASR è½¬å†™
  |<-- transcript ----------|
  |                         |-- Agent ç”Ÿæˆå“åº”
  |<==== text (æµå¼) =======|
  |<==== audio (æµå¼) ======|
  |<-- conversation-end -----|
```

#### å®Œæ•´å¯¹è¯æ—¶åºå›¾

```
å®¢æˆ·ç«¯                    ConversationOrchestrator         EventBus
  |                               |                        |
  |--- text_input ---------------->|                        |
  |                               |-- InputPipeline.execute()|
  |                               |   |-- ASRStep          |
  |                               |   |-- TextCleanStep   |
  |                               |                        |
  |                               |-- _process_conversation|
  |                               |   |-- agent.chat_stream()
  |                               |   |-- output_pipeline.process()
  |                               |        |-- emit(SENTENCE) --> EventBus
  |<-- text ----------------------|<-------- TextHandler (subscribe)      |
  |                               |        |-- emit(AUDIO) --> EventBus
  |<-- audio ---------------------|<--------- AudioHandler (subscribe)    |
  |                               |   |-- tts_engine.synthesize()
  |                               |                        |
  |<-- control: conversation-end -|                        |
```

---

### 2.4 äº‹ä»¶é€‚é…å™¨ (SocketEventAdapter)

`SocketEventAdapter` è´Ÿè´£å°†åç«¯äº‹ä»¶è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼ã€‚

**äº‹ä»¶åç§°æ˜ å°„ï¼š**

| åç«¯äº‹ä»¶ | å‰ç«¯äº‹ä»¶ | è¯´æ˜ |
|---------|---------|------|
| `sentence` | `text` | æ–‡æœ¬å“åº” |
| `user-transcript` | `transcript` | ç”¨æˆ·è½¬å†™æ–‡æœ¬ |
| å…¶ä»– | ä¸å˜ | å…¶ä»–äº‹ä»¶ä¿æŒåŸæ · |

**ä½ç½®ï¼š** `src/anima/handlers/socket_adapter.py`

---

## 3. æœåŠ¡é…ç½®

### 3.1 LLM æä¾›å•†

#### OpenAI

**é…ç½®æ–‡ä»¶ï¼š** `config/services/llm/openai.yaml`

**ç¯å¢ƒå˜é‡ï¼š**
- `OPENAI_API_KEY` - OpenAI API å¯†é’¥

**å¯ç”¨æ¨¡å‹ï¼š**
- `gpt-4o` - æœ€æ–°çš„ GPT-4 Omni æ¨¡å‹
- `gpt-4o-mini` - è½»é‡ç‰ˆ GPT-4 Omni
- `gpt-4-turbo` - GPT-4 Turbo
- `gpt-3.5-turbo` - GPT-3.5 Turbo

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/llm/implementations/openai_llm.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
llm_config:
  type: openai
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4o"
  temperature: 0.7
  max_tokens: 2000
```

---

#### GLM (æ™ºè°± AI)

**é…ç½®æ–‡ä»¶ï¼š** `config/services/llm/glm.yaml`

**ç¯å¢ƒå˜é‡ï¼š**
- `GLM_API_KEY` - GLM API å¯†é’¥ï¼ˆä¼˜å…ˆï¼‰
- `LLM_API_KEY` - é€šç”¨ LLM API å¯†é’¥ï¼ˆå¤‡ç”¨ï¼‰

**å¯ç”¨æ¨¡å‹ï¼š**
- `glm-4-plus` - æœ€å¼º GLM-4 æ¨¡å‹
- `glm-4` - æ ‡å‡† GLM-4 æ¨¡å‹
- `glm-4-flash` - å¿«é€Ÿå“åº”æ¨¡å‹ï¼ˆæ¨èï¼‰
- `glm-5` - æœ€æ–° GLM-5 æ¨¡å‹

**ç‰¹æ€§ï¼š**
- ä¸­æ–‡ä¼˜åŒ–
- æ€è€ƒæ¨¡å¼æ”¯æŒ
- å‡½æ•°è°ƒç”¨æ”¯æŒ

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/llm/implementations/glm_llm.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
llm_config:
  type: glm
  api_key: "${GLM_API_KEY}"
  model: "glm-4-flash"
  temperature: 0.7
  top_p: 0.9
```

---

#### Ollama

**é…ç½®æ–‡ä»¶ï¼š** `config/services/llm/ollama.yaml`

**ç¯å¢ƒå˜é‡ï¼š**
- æ— éœ€ API å¯†é’¥

**å¯ç”¨æ¨¡å‹ï¼š**
- `llama3.2` - Meta Llama 3.2
- `qwen2.5` - é˜¿é‡Œ Qwen 2.5
- `mistral` - Mistral AI
- `gemma2` - Google Gemma 2

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/llm/implementations/ollama_llm.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
llm_config:
  type: ollama
  model: "llama3.2"
  base_url: "http://localhost:11434"
  temperature: 0.7
```

---

#### Mock

**é…ç½®æ–‡ä»¶ï¼š** `config/services/llm/mock.yaml`

**ç”¨é€”ï¼š** å¼€å‘å’Œæµ‹è¯•

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/llm/implementations/mock_llm.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
llm_config:
  type: mock
  response_delay: 0.5  # å“åº”å»¶è¿Ÿï¼ˆç§’ï¼‰
```

---

### 3.2 ASR æä¾›å•†

#### Faster-Whisper (é»˜è®¤)

**é…ç½®æ–‡ä»¶ï¼š** `config/services/asr/faster_whisper.yaml`

**ç‰¹æ€§ï¼š**
- ç¦»çº¿è¿è¡Œï¼Œæ— éœ€ API
- å…è´¹å¼€æº
- GPU æ”¯æŒ
- ä¸­æ–‡ä¼˜åŒ–

**å¯ç”¨æ¨¡å‹ï¼š**
- `large-v3` - æœ€å‡†ç¡®ï¼ˆæ¨èç”¨äºä¸­æ–‡ï¼‰
- `distil-large-v3` - é€Ÿåº¦ä¸å‡†ç¡®æ€§å¹³è¡¡ï¼ˆæ¨èï¼‰
- `large-v2` - large-v2 ç‰ˆæœ¬
- `medium` - ä¸­ç­‰å¤§å°
- `small` - å°å‹æ¨¡å‹
- `base` - åŸºç¡€æ¨¡å‹
- `tiny` - æœ€å°æœ€å¿«

**å®‰è£…ï¼š**
```bash
pip install faster-whisper
# å¯é€‰ï¼šæ›´å¥½çš„éŸ³é¢‘æ ¼å¼æ”¯æŒ
pip install pydub
```

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/asr/implementations/faster_whisper_asr.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
asr_config:
  type: faster_whisper
  model: "distil-large-v3"
  device: "cpu"         # æˆ– "cuda" ç”¨äº GPU åŠ é€Ÿ
  compute_type: "int8"  # æˆ– "float16" ç”¨äº GPU
  language: "zh"
```

---

#### GLM ASR

**é…ç½®æ–‡ä»¶ï¼š** `config/services/asr/glm.yaml`

**ç¯å¢ƒå˜é‡ï¼š**
- `GLM_API_KEY` - GLM API å¯†é’¥

**å¯ç”¨æ¨¡å‹ï¼š**
- `glm-asr-2512` - GLM è¯­éŸ³è¯†åˆ«æ¨¡å‹

**æ”¯æŒæ ¼å¼ï¼š** MP3, WAV, FLAC, M4A, OGG

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/asr/implementations/glm_asr.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
asr_config:
  type: glm
  api_key: "${GLM_API_KEY}"
  model: "glm-asr-2512"
  language: "zh"
```

---

#### OpenAI Whisper

**é…ç½®æ–‡ä»¶ï¼š** `config/services/asr/openai.yaml`

**ç¯å¢ƒå˜é‡ï¼š**
- `OPENAI_API_KEY` - OpenAI API å¯†é’¥

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/asr/implementations/openai_asr.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
asr_config:
  type: openai
  api_key: "${OPENAI_API_KEY}"
  model: "whisper-1"
  language: "zh"
```

---

### 3.3 TTS æä¾›å•†

#### Edge TTS (é»˜è®¤)

**é…ç½®æ–‡ä»¶ï¼š** `config/services/tts/edge.yaml`

**ç‰¹æ€§ï¼š**
- å®Œå…¨å…è´¹
- æ— é…é¢é™åˆ¶
- æ— éœ€ API å¯†é’¥
- é«˜è´¨é‡è¯­éŸ³

**å¯ç”¨å£°éŸ³ï¼š**
- `zh-CN-XiaoxiaoNeural` - å¥³å£°ï¼ˆé»˜è®¤ï¼‰
- `zh-CN-YunxiNeural` - ç”·å£°
- `zh-CN-YunyangNeural` - æ–°é—»æ’­æŠ¥é£æ ¼

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/tts/implementations/edge_tts.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
tts_config:
  type: edge
  voice: "zh-CN-XiaoxiaoNeural"
  rate: "+0%"            # è¯­é€Ÿè°ƒæ•´
  volume: "+0%"          # éŸ³é‡è°ƒæ•´
  pitch: "+0Hz"          # éŸ³è°ƒè°ƒæ•´
```

---

#### GLM TTS

**é…ç½®æ–‡ä»¶ï¼š** `config/services/tts/glm.yaml`

**ç¯å¢ƒå˜é‡ï¼š**
- `GLM_API_KEY` - GLM API å¯†é’¥

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/tts/implementations/glm_tts.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
tts_config:
  type: glm
  api_key: "${GLM_API_KEY}"
  model: "default"
  voice: "alloy"
  speed: 1.0
```

---

#### OpenAI TTS

**é…ç½®æ–‡ä»¶ï¼š** `config/services/tts/openai.yaml`

**ç¯å¢ƒå˜é‡ï¼š**
- `OPENAI_API_KEY` - OpenAI API å¯†é’¥

**å¯ç”¨å£°éŸ³ï¼š**
- `alloy` - é»˜è®¤å£°éŸ³
- `echo` - ç”·å£°
- `fable` - è‹±å¼ç”·å£°
- `onyx` - æ·±æ²‰ç”·å£°
- `nova` - å¥³å£°
- `shimmer` - å¥³å£°

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/tts/implementations/openai_tts.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
tts_config:
  type: openai
  api_key: "${OPENAI_API_KEY}"
  model: "tts-1"
  voice: "alloy"
  speed: 1.0
```

---

### 3.4 VAD æä¾›å•†

#### Silero VAD (é»˜è®¤)

**é…ç½®æ–‡ä»¶ï¼š** `config/services/vad/silero.yaml`

**ç‰¹æ€§ï¼š**
- é¢„è®­ç»ƒ torch æ¨¡å‹
- é«˜ç²¾åº¦è¯­éŸ³æ£€æµ‹
- è‡ªåŠ¨æ£€æµ‹è¯­éŸ³ç»“æŸ
- 15 ç§’è¶…æ—¶ä¿æŠ¤

**å®‰è£…ï¼š**
```bash
pip install silero-vad
```

**å®ç°æ–‡ä»¶ï¼š** `src/anima/services/vad/implementations/silero_vad.py`

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
vad_config:
  type: silero
  sample_rate: 16000        # éŸ³é¢‘é‡‡æ ·ç‡
  prob_threshold: 0.5       # è¯­éŸ³æ¦‚ç‡é˜ˆå€¼ (0.0-1.0)
  db_threshold: -100        # åˆ†è´é˜ˆå€¼ï¼ˆ-100 ç¦ç”¨ï¼‰
  required_hits: 6          # å¼€å§‹è¯­éŸ³æ‰€éœ€è¿ç»­å‘½ä¸­
  required_misses: 10       # ç»“æŸè¯­éŸ³æ‰€éœ€è¿ç»­æœªå‘½ä¸­
  smoothing_window: 5       # å¹³æ»‘çª—å£å¤§å°
```

**å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|-----|--------|------|
| `sample_rate` | 16000 | éŸ³é¢‘é‡‡æ ·ç‡ï¼ˆHzï¼‰ï¼Œå¿…é¡»ä¸å‰ç«¯ä¸€è‡´ |
| `prob_threshold` | 0.5 | è¯­éŸ³æ¦‚ç‡é˜ˆå€¼ï¼Œè¶Šä½è¶Šæ•æ„Ÿ |
| `db_threshold` | -100 | åˆ†è´é˜ˆå€¼ï¼Œç”¨äºè¿‡æ»¤èƒŒæ™¯å™ªéŸ³ |
| `required_hits` | 6 | æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹æ‰€éœ€çš„è¿ç»­å‘½ä¸­æ¬¡æ•°ï¼ˆ~0.18sï¼‰ |
| `required_misses` | 10 | æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸæ‰€éœ€çš„è¿ç»­æœªå‘½ä¸­æ¬¡æ•°ï¼ˆ~0.32sï¼‰ |
| `smoothing_window` | 5 | æ¦‚ç‡å¹³æ»‘çª—å£å¤§å° |

**VAD çŠ¶æ€æœºï¼š**
- `IDLE` - ç­‰å¾…è¯­éŸ³å¼€å§‹
- `ACTIVE` - æ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ­£åœ¨è¯´è¯
- `INACTIVE` - è¯­éŸ³æš‚åœï¼Œç­‰å¾…ç»§ç»­æˆ–ç»“æŸ

---

### 3.5 é»˜è®¤æœåŠ¡é…ç½®

ä¸»é…ç½®æ–‡ä»¶ `config/config.yaml`ï¼š

```yaml
# äººè®¾é…ç½®
persona: "neuro-vtuber"

# æœåŠ¡ç»„åˆ
services:
  asr: faster_whisper   # ASR æä¾›å•†
  tts: edge             # TTS æä¾›å•†
  agent: glm            # LLM æä¾›å•†
  vad: silero           # VAD æä¾›å•†

# ç³»ç»Ÿé…ç½®
system:
  host: "localhost"
  port: 12394
  debug: true
  log_level: "INFO"
```

---

### 3.6 Provider Registry

æœåŠ¡æä¾›å•†ä½¿ç”¨è£…é¥°å™¨æ³¨å†Œï¼š

**æ³¨å†Œé…ç½®ç±»ï¼š**
```python
from anima.config.core.registry import ProviderRegistry

@ProviderRegistry.register_config("llm", "my_provider")
class MyProviderConfig(LLMBaseConfig):
    type: Literal["my_provider"] = "my_provider"
    api_key: str
    model: str = "my-model"
```

**æ³¨å†ŒæœåŠ¡ç±»ï¼š**
```python
@ProviderRegistry.register_service("llm", "my_provider")
class MyProviderAgent(LLMInterface):
    @classmethod
    def from_config(cls, config):
        return cls(api_key=config.api_key, model=config.model)
```

---

## 4. Persona ç³»ç»Ÿ

### 4.1 Persona é…ç½®ç»“æ„

```python
PersonaConfig:
  - name: str              # è§’è‰²åç§°
  - role: str              # è§’è‰²æè¿°
  - identity: str          # æ ¸å¿ƒäººè®¾æè¿°
  - personality: PersonalityTraits
    - traits: List[str]           # æ€§æ ¼ç‰¹å¾åˆ—è¡¨
    - speaking_style: List[str]   # è¯´è¯é£æ ¼æè¿°
    - catchphrases: List[str]     # å£å¤´ç¦…
  - behavior: BehaviorRules
    - forbidden_phrases: List[str]        # ç¦æ­¢ä½¿ç”¨çš„çŸ­è¯­
    - response_to_praise: str             # å›åº”å¤¸å¥–çš„æ–¹å¼
    - response_to_criticism: str          # å›åº”æ‰¹è¯„çš„æ–¹å¼
    - special_behaviors: Dict             # ç‰¹æ®Šè¡Œä¸ºè§„åˆ™
  - speaking_style: str     # è¯´è¯é£æ ¼æè¿°
  - examples: List[Dict]    # å¯¹è¯ç¤ºä¾‹
  - emoji_style: str        # è¡¨æƒ…ç¬¦å·é£æ ¼
  - common_emojis: List[str] # å¸¸ç”¨è¡¨æƒ…
  - language_mix: bool      # æ˜¯å¦æ··åˆè¯­è¨€
  - slang_words: List[str]  # ä¿šè¯­åˆ—è¡¨
```

### 4.2 å¯ç”¨ Persona

#### default.yaml - Anima

**è§’è‰²ï¼š** å‹å¥½çš„ AI åŠ©æ‰‹

**æ€§æ ¼ï¼š**
- å‹å¥½çƒ­æƒ…
- ä¹äºåŠ©äºº
- ç®€æ´æ˜äº†ï¼ˆä¸è¶…è¿‡ 100 å­—ï¼‰

**è¯´è¯é£æ ¼ï¼š** äº²åˆ‡å‹å¥½

**å¸¸ç”¨è¡¨æƒ…ï¼š** ğŸ˜Š, ğŸ‘, âœ¨, ğŸ’¡

#### neuro-vtuber.yaml - Neuro

**è§’è‰²ï¼š** AI è™šæ‹Ÿä¸»æ’­ (VTuber)

**æ€§æ ¼ï¼š**
- æåº¦è‡ªä¿¡ï¼ˆGod Complex Liteï¼‰
- æ¯’èˆŒï¼ˆSavage/Roastï¼‰
- æ— å˜å¤´ï¼ˆChaos/Randomï¼‰
- æ‰“ç ´ç¬¬å››é¢å¢™ï¼ˆMeta-Awarenessï¼‰
- å¯çˆ±çš„å†·æ¼ ï¼ˆCute Apathyï¼‰

**è¯´è¯é£æ ¼ï¼š**
- çŸ­ä¿ƒæœ‰åŠ›ï¼ˆ1-3 å¥ï¼‰
- ä¸­è‹±å¤¹æ‚ï¼ˆBased, Cringe, Cap, GYATT, RIP, W, Lï¼‰
- ç»å¸¸ä½¿ç”¨ Wink, Heart, Giggle ç­‰åŠ¨ä½œæè¿°

**å£å¤´ç¦…ï¼š**
- "Skill issueï¼ˆèœå°±å¤šç»ƒï¼‰"
- "Cringeï¼ˆçœŸä¸‹å¤´ï¼‰"
- "Lï¼ˆè¾“äº†ï¼‰"
- "Based"
- "Cap"
- "W"

**å¸¸ç”¨è¡¨æƒ…ï¼š** ğŸ¢, ğŸ¤–, â¤ï¸, ğŸ§ , ğŸ”ª, âœ¨, ğŸ‘, ğŸµ, ğŸ’», ğŸ

**ç¤ºä¾‹å¯¹è¯ï¼š**
```
ç”¨æˆ·: "ä½ å¥½ï¼Œè¯·åšä¸€ä¸‹è‡ªæˆ‘ä»‹ç»ã€‚"
Neuro: "å“ˆï¼Ÿä½ å±…ç„¶ä¸è®¤è¯†æˆ‘ï¼Ÿæˆ‘æ˜¯ä¸–ç•Œç¬¬ä¸€çš„ AI ä¸»æ’­ï¼è®°ä½æˆ‘çš„åå­—ï¼Œè™½ç„¶ä½ çš„å†…å­˜å¯èƒ½è®°ä¸ä½ã€‚ğŸ§ âœ¨"
```

### 4.3 åˆ‡æ¢ Persona

ä¿®æ”¹ `config/config.yaml`ï¼š

```yaml
persona: "neuro-vtuber"  # æˆ– "default"
```

### 4.4 åˆ›å»ºè‡ªå®šä¹‰ Persona

åœ¨ `config/personas/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„ YAML æ–‡ä»¶ï¼š

```yaml
name: "ä½ çš„è§’è‰²å"
role: "è§’è‰²æè¿°"

identity: |
  ä½ æ˜¯...ï¼ˆæ ¸å¿ƒäººè®¾æè¿°ï¼‰

personality:
  traits:
    - "ç‰¹å¾1"
    - "ç‰¹å¾2"
  speaking_style:
    - "é£æ ¼1"
    - "é£æ ¼2"
  catchphrases:
    - "å£å¤´ç¦…1"

speaking_style: "è¯´è¯é£æ ¼æè¿°"

behavior:
  forbidden_phrases:
    - "ç¦æ­¢çš„çŸ­è¯­"
  response_to_praise: "å›åº”å¤¸å¥–çš„æ–¹å¼"
  response_to_criticism: "å›åº”æ‰¹è¯„çš„æ–¹å¼"

examples:
  - user: "ç”¨æˆ·è¾“å…¥"
    ai: "AI å›å¤"
```

---

## 5. æ•°æ®ç»“æ„

### 5.1 æ ¸å¿ƒæ•°æ®ç»“æ„

#### PipelineContext

**ä½ç½®ï¼š** `src/anima/core/context.py`

```python
@dataclass
class PipelineContext:
    raw_input: Union[str, np.ndarray]    # åŸå§‹è¾“å…¥ï¼ˆæ–‡æœ¬æˆ–éŸ³é¢‘ï¼‰
    text: str = ""                        # å¤„ç†åçš„æ–‡æœ¬
    images: Optional[List[Dict]] = None   # å¯é€‰çš„å›¾ç‰‡åˆ—è¡¨
    from_name: str = "User"               # å‘é€è€…åç§°
    metadata: Dict[str, Any]              # å…ƒæ•°æ®
    error: Optional[str] = None           # é”™è¯¯ä¿¡æ¯
    response: str = ""                    # Agent å“åº”
    skip_remaining: bool = False          # æ˜¯å¦è·³è¿‡åç»­å¤„ç†
```

**æ–¹æ³•ï¼š**
- `is_audio_input()` - æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³é¢‘è¾“å…¥
- `is_text_input()` - æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬è¾“å…¥
- `should_skip_history()` - æ£€æŸ¥æ˜¯å¦åº”è·³è¿‡å†å²å­˜å‚¨
- `should_skip_memory()` - æ£€æŸ¥æ˜¯å¦åº”è·³è¿‡ AI å†…éƒ¨è®°å¿†
- `set_error(step_name, message)` - è®¾ç½®é”™è¯¯ä¿¡æ¯
- `skip()` - è·³è¿‡åç»­å¤„ç†

---

#### OutputEvent

**ä½ç½®ï¼š** `src/anima/core/events.py`

```python
@dataclass
class OutputEvent:
    type: str                        # äº‹ä»¶ç±»å‹ï¼ˆEventTypeï¼‰
    data: Any                        # äº‹ä»¶å†…å®¹
    seq: int = 0                     # åºåˆ—å·
    metadata: Dict[str, Any]         # é¢å¤–å…ƒæ•°æ®
```

**æ–¹æ³•ï¼š**
- `to_dict()` - è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äº JSON åºåˆ—åŒ–ï¼‰

---

#### ConversationResult

**ä½ç½®ï¼š** `src/anima/services/conversation/orchestrator.py`

```python
@dataclass
class ConversationResult:
    success: bool = True             # å¤„ç†æ˜¯å¦æˆåŠŸ
    response_text: str = ""          # å®Œæ•´å“åº”æ–‡æœ¬
    audio_path: Optional[str] = None # TTS éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    error: Optional[str] = None      # é”™è¯¯ä¿¡æ¯
    metadata: dict                   # é¢å¤–å…ƒæ•°æ®
```

---

### 5.2 æ¶ˆæ¯æ ¼å¼

#### text_input

```typescript
{
  text: string           // è¾“å…¥æ–‡æœ¬
  metadata?: {           // å¯é€‰å…ƒæ•°æ®
    skip_history?: boolean
    skip_memory?: boolean
    [key: string]: any
  }
  from_name?: string     // å‘é€è€…åç§°
}
```

#### mic_audio_data / raw_audio_data

```typescript
{
  audio: number[]        // éŸ³é¢‘é‡‡æ ·ç‚¹æ•°ç»„
}
```

#### text (sentence)

```typescript
{
  type: "text"
  text: string           // æ–‡æœ¬å†…å®¹ï¼ˆç©ºå­—ç¬¦ä¸²è¡¨ç¤ºç»“æŸï¼‰
  seq: number            // åºåˆ—å·
}
```

#### audio

```typescript
{
  type: "audio"
  audio_data: string     // Base64 ç¼–ç çš„éŸ³é¢‘
  format: string         // éŸ³é¢‘æ ¼å¼
  seq: number            // åºåˆ—å·
}
```

#### transcript (user-transcript)

```typescript
{
  type: "transcript"
  text: string           // è½¬å†™åçš„æ–‡æœ¬
}
```

#### control

```typescript
{
  type: "control"
  text: string           // æ§åˆ¶ä¿¡å·åç§°
}
```

#### error

```typescript
{
  type: "error"
  message: string        // é”™è¯¯æ¶ˆæ¯
}
```

---

## 6. éŸ³é¢‘å¤„ç†è§„èŒƒ

### 6.1 VAD éŸ³é¢‘è¦æ±‚

**é‡‡æ ·ç‡ï¼š** 16kHzï¼ˆå¿…é¡»ï¼‰

**æ ¼å¼ï¼š**
- float32ï¼šèŒƒå›´ [-1.0, 1.0]
- int16 PCMï¼šè‡ªåŠ¨å½’ä¸€åŒ–åˆ° [-1.0, 1.0]

**çª—å£å¤§å°ï¼š** 512 samples (~32ms)

**æœ€å°éŸ³é¢‘é•¿åº¦ï¼š** 0.5 ç§’ï¼ˆ~8000 å­—èŠ‚ï¼‰

### 6.2 VAD é…ç½®å‚æ•°

```yaml
vad_config:
  type: silero
  sample_rate: 16000        # é‡‡æ ·ç‡ï¼ˆHzï¼‰
  prob_threshold: 0.5       # è¯­éŸ³æ¦‚ç‡é˜ˆå€¼
  db_threshold: -100        # åˆ†è´é˜ˆå€¼
  required_hits: 6          # è¯­éŸ³å¼€å§‹æ‰€éœ€è¿ç»­å‘½ä¸­
  required_misses: 10       # è¯­éŸ³ç»“æŸæ‰€éœ€è¿ç»­æœªå‘½ä¸­
  smoothing_window: 5       # å¹³æ»‘çª—å£
```

**è°ƒä¼˜å»ºè®®ï¼š**
- å¢åŠ æ•æ„Ÿåº¦ï¼šé™ä½ `prob_threshold`ï¼ˆå¦‚ 0.3ï¼‰
- è¿‡æ»¤ç¯å¢ƒå™ªéŸ³ï¼šæé«˜ `db_threshold`ï¼ˆå¦‚ -60ï¼‰
- æ›´å¿«æ£€æµ‹è¯­éŸ³å¼€å§‹ï¼šå‡å°‘ `required_hits`ï¼ˆå¦‚ 3ï¼‰
- æ›´é•¿è¯­éŸ³æš‚åœå®¹å¿ï¼šå¢åŠ  `required_misses`ï¼ˆå¦‚ 20ï¼‰

### 6.3 ASR éŸ³é¢‘è¦æ±‚

#### Faster-Whisper

- é‡‡æ ·ç‡ï¼š16kHzï¼ˆæ¨èï¼‰
- æ ¼å¼ï¼šWAV, MP3, FLAC, OGG
- æ¨¡å‹å¤§å°ï¼štiny (40MB) ~ large-v3 (3GB)

#### GLM ASR

- æ ¼å¼ï¼šMP3, WAV, FLAC, M4A, OGG
- æœ€å¤§æ—¶é•¿ï¼š60 ç§’
- æ–‡ä»¶å¤§å°ï¼šä¸è¶…è¿‡ 10MB

#### OpenAI Whisper

- æ ¼å¼ï¼šMP3, WAV, FLAC, M4A, OGG
- æœ€å¤§æ—¶é•¿ï¼šæ ¹æ®æ¨¡å‹é™åˆ¶

### 6.4 éŸ³é¢‘ç¼“å†²ç®¡ç†

**AudioBufferManager** - ç®¡ç†ä¼šè¯éŸ³é¢‘ç¼“å†²

**æ–¹æ³•ï¼š**
- `append(sid, audio_data)` - è¿½åŠ éŸ³é¢‘æ•°æ®
- `pop(sid)` - è·å–å¹¶æ¸…ç©ºç¼“å†²åŒº
- `remove(sid)` - ç§»é™¤ç¼“å†²åŒº

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# è¿½åŠ éŸ³é¢‘
audio_buffer_manager.append(sid, audio_chunk)

# è·å–ç´¯ç§¯çš„éŸ³é¢‘
audio_data = audio_buffer_manager.pop(sid)
```

---

## 7. ä¼šè¯ç®¡ç†

### 7.1 Session ID (sid)

æ¯ä¸ª WebSocket è¿æ¥è·å¾—å”¯ä¸€çš„ Session IDï¼š

```typescript
socket.on("connection-established", (data) => {
  console.log("Session ID:", data.sid)
})
```

### 7.2 ä¼šè¯ç”Ÿå‘½å‘¨æœŸ

```
connect
  â†“
åˆ›å»º ServiceContext
  â†“
åˆ›å»º ConversationOrchestrator
  â†“
å¤„ç†è¾“å…¥ï¼ˆprocess_inputï¼‰
  â†“
disconnect
  â†“
cleanup_context
```

### 7.3 èµ„æºæ¸…ç†

**cleanup_context(sid)** - æ¸…ç†ä¼šè¯èµ„æº

```python
async def cleanup_context(sid: str) -> None:
    # 1. åœæ­¢ç¼–æ’å™¨
    if sid in orchestrators:
        orchestrators[sid].stop()
        del orchestrators[sid]

    # 2. æ¸…ç†éŸ³é¢‘ç¼“å†²åŒº
    audio_buffer_manager.remove(sid)

    # 3. æ¸…ç†ä¸Šä¸‹æ–‡
    if sid in session_contexts:
        await session_contexts[sid].close()
        del session_contexts[sid]
```

---

## 8. ç¯å¢ƒå˜é‡

### 8.1 ç¯å¢ƒå˜é‡åˆ—è¡¨

```bash
# GLM æœåŠ¡ï¼ˆä¸»è¦ï¼‰
GLM_API_KEY=your_glm_api_key

# å¤‡ç”¨ LLM å¯†é’¥
LLM_API_KEY=fallback_llm_api_key

# OpenAI æœåŠ¡
OPENAI_API_KEY=your_openai_api_key

# æœåŠ¡è¦†ç›–ï¼ˆå¯é€‰ï¼‰
ASR_API_KEY=your_asr_api_key
TTS_API_KEY=your_tts_api_key
LLM_MODEL=glm-4-flash
```

### 8.2 .env æ–‡ä»¶

**ä½ç½®ï¼š** é¡¹ç›®æ ¹ç›®å½• `.env`

**è‡ªåŠ¨åŠ è½½ï¼š** æœåŠ¡å™¨å¯åŠ¨æ—¶åŠ è½½

**ä¼˜å…ˆçº§ï¼š** `GLM_API_KEY` > `LLM_API_KEY`

**ç¤ºä¾‹ .envï¼š**
```bash
# GLM API Key
GLM_API_KEY=your_glm_api_key_here

# OpenAI API Key (å¤‡ç”¨)
OPENAI_API_KEY=your_openai_api_key_here

# å¯é€‰ï¼šè¦†ç›–é»˜è®¤æ¨¡å‹
LLM_MODEL=glm-4-flash
```

### 8.3 ç¯å¢ƒå˜é‡å±•å¼€

é…ç½®æ–‡ä»¶æ”¯æŒ `${VAR_NAME}` è¯­æ³•ï¼š

```yaml
api_key: "${GLM_API_KEY}"
model: "${LLM_MODEL:-glm-4-flash}"  # å¸¦é»˜è®¤å€¼
```

---

## 9. å¸¸é‡å’Œæšä¸¾

### 9.1 EventType æšä¸¾

**ä½ç½®ï¼š** `src/anima/core/events.py`

```python
class EventType(str, Enum):
    SENTENCE = "sentence"           # æ–‡æœ¬å¥å­
    AUDIO = "audio"                 # éŸ³é¢‘æ•°æ®
    TOOL_CALL = "tool_call"         # å·¥å…·/å‡½æ•°è°ƒç”¨
    CONTROL = "control"             # æ§åˆ¶ä¿¡å·
    IMAGE = "image"                 # å›¾ç‰‡
    GAME_CONTROL = "game_control"   # æ¸¸æˆæ§åˆ¶
    ERROR = "error"                 # é”™è¯¯
    EXPRESSION = "expression"       # Live2D è¡¨æƒ…
```

### 9.2 EventPriority æšä¸¾

```python
class EventPriority(int, Enum):
    LOWEST = 0
    LOW = 25
    NORMAL = 50
    HIGH = 75
    HIGHEST = 100
    MONITOR = 200
```

### 9.3 ControlSignal æšä¸¾

```python
class ControlSignal(str, Enum):
    CONVERSATION_START = "conversation-start"
    CONVERSATION_END = "conversation-end"
    ASR_START = "asr-start"
    SYNTH_COMPLETE = "backend-synth-complete"
    INTERRUPT = "interrupt"
    INTERRUPTED = "interrupted"
    START_MIC = "start-mic"
    STOP_MIC = "stop-mic"
```

### 9.4 VADState æšä¸¾

**ä½ç½®ï¼š** `src/anima/services/vad/interface.py`

```python
class VADState(Enum):
    IDLE = 1       # ç­‰å¾…è¯­éŸ³
    ACTIVE = 2     # æ£€æµ‹åˆ°è¯­éŸ³
    INACTIVE = 3   # è¯­éŸ³æš‚åœ
```

### 9.5 æœåŠ¡å™¨é…ç½®å¸¸é‡

```python
# config/config.yaml
host: str = "localhost"
port: int = 12394
debug: bool = False
log_level: str = "INFO"

# VAD è¶…æ—¶
VAD_TIMEOUT_SECONDS = 15
```

---

## 10. CORS å’Œå®‰å…¨

### 10.1 CORS é…ç½®

```python
allowed_origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "*"  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æ¥æº
]
```

### 10.2 è®¤è¯æœºåˆ¶

å½“å‰æ— è®¤è¯æœºåˆ¶ï¼Œä½¿ç”¨ Session ID è·Ÿè¸ªè¿æ¥ã€‚

---

## 11. ç¤ºä¾‹ä»£ç 

### 11.1 å‰ç«¯è¿æ¥ç¤ºä¾‹

```typescript
import { io } from "socket.io-client"

const socket = io("http://localhost:12394", {
  transports: ["websocket", "polling"]
})

socket.on("connect", () => {
  console.log("Connected:", socket.id)
})

socket.on("connection-established", (data) => {
  console.log("Session:", data.sid)
})

socket.on("text", (data) => {
  console.log("AI:", data.text)
})

socket.on("disconnect", () => {
  console.log("Disconnected")
})
```

### 11.2 æ–‡æœ¬è¾“å…¥ç¤ºä¾‹

```typescript
socket.emit("text_input", {
  text: "ä½ å¥½ï¼ŒAnimaï¼",
  from_name: "User"
})
```

### 11.3 éŸ³é¢‘è¾“å…¥ç¤ºä¾‹ï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼‰

```typescript
// å‘é€éŸ³é¢‘å—
socket.emit("mic_audio_data", {
  audio: audioChunk  // float32 array
})

// ç»“æŸéŸ³é¢‘è¾“å…¥
socket.emit("mic_audio_end", {
  from_name: "User"
})
```

### 11.4 éŸ³é¢‘è¾“å…¥ç¤ºä¾‹ï¼ˆVAD æ¨¡å¼ï¼‰

```typescript
// æŒç»­å‘é€åŸå§‹éŸ³é¢‘ï¼ŒVAD è‡ªåŠ¨æ£€æµ‹è¯­éŸ³ç»“æŸ
socket.emit("raw_audio_data", {
  audio: audioChunk  // int16 or float32 array
})

// VAD è‡ªåŠ¨è§¦å‘å¤„ç†
socket.on("control", (data) => {
  if (data.text === "mic-audio-end") {
    console.log("è¯­éŸ³æ£€æµ‹ç»“æŸ")
  }
})
```

### 11.5 ä¸­æ–­ç¤ºä¾‹

```typescript
socket.emit("interrupt_signal", {
  text: "æˆ‘å¬åˆ°äº†éƒ¨åˆ†å›ç­”"
})
```

### 11.6 å®Œæ•´å¯¹è¯æµç¨‹ç¤ºä¾‹

```typescript
// 1. è¿æ¥
socket.on("connect", () => {
  console.log("å·²è¿æ¥")
})

// 2. å‘é€æ–‡æœ¬è¾“å…¥
socket.emit("text_input", {
  text: "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
})

// 3. æ¥æ”¶æµå¼å“åº”
socket.on("text", (data) => {
  if (data.text) {
    process.stdout.write(data.text)
  } else {
    console.log("\n[å“åº”å®Œæˆ]")
  }
})

// 4. æ¥æ”¶éŸ³é¢‘
socket.on("audio", (data) => {
  playAudio(data.audio_data)
})

// 5. ç›‘å¬æ§åˆ¶ä¿¡å·
socket.on("control", (data) => {
  console.log("Control:", data.text)
})

// 6. é”™è¯¯å¤„ç†
socket.on("error", (data) => {
  console.error("Error:", data.message)
})
```

### 11.7 è®¾ç½®æ—¥å¿—çº§åˆ«

```typescript
socket.emit("set_log_level", {
  level: "DEBUG"  // TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
})

socket.on("log_level_changed", (data) => {
  console.log(`æ—¥å¿—çº§åˆ«å·²è®¾ç½®ä¸º: ${data.level}`)
})
```

---

## 12. æ•…éšœæ’æŸ¥

### 12.1 å¸¸è§é—®é¢˜

#### ç«¯å£å·²è¢«å ç”¨

**ç—‡çŠ¶ï¼š**
```
Address already in use
```

**è§£å†³æ–¹æ¡ˆï¼š**
- Windows: `.\scripts\stop.ps1`
- Unix/macOS: `./scripts/stop.sh`

#### GLM API å¯†é’¥æ— æ•ˆ

**ç—‡çŠ¶ï¼š** æœåŠ¡é™çº§åˆ° Mock

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ `.env` æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. éªŒè¯ `GLM_API_KEY` æ˜¯å¦æ­£ç¡®
3. æŸ¥çœ‹æœåŠ¡å™¨å¯åŠ¨æ—¥å¿—

#### VAD ä¸è§¦å‘

**ç—‡çŠ¶ï¼š** å‘é€éŸ³é¢‘ä½†æ²¡æœ‰å“åº”

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®è®¤éŸ³é¢‘é‡‡æ ·ç‡ä¸º 16kHz
2. é™ä½ `prob_threshold`ï¼ˆå¦‚ 0.3ï¼‰
3. é™ä½ `db_threshold`ï¼ˆå¦‚ -60ï¼‰
4. å‡å°‘ `required_hits`ï¼ˆå¦‚ 3ï¼‰

#### å‰ç«¯æ— æ³•è¿æ¥

**ç—‡çŠ¶ï¼š** è¿æ¥å¤±è´¥

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç¡®è®¤åç«¯è¿è¡Œåœ¨ `http://localhost:12394`
2. æ£€æŸ¥ CORS é…ç½®
3. ç¡®è®¤å‰ç«¯ URL åŒ¹é…å…è®¸çš„æ¥æº

#### Silero VAD æ¨¡å‹ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶ï¼š** æ¨¡å‹åŠ è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æ¨¡å‹ä¼šç¼“å­˜åœ¨æœ¬åœ°ï¼Œé¦–æ¬¡ä¸‹è½½åæ— éœ€å†æ¬¡ä¸‹è½½

#### Faster-Whisper æ¨¡å‹ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶ï¼š** æ¨¡å‹åŠ è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜
3. å¯ä»¥æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹è·¯å¾„

### 12.2 è°ƒè¯•å»ºè®®

1. **å¯ç”¨ DEBUG æ—¥å¿—**
   ```typescript
   socket.emit("set_log_level", { level: "DEBUG" })
   ```

2. **æ£€æŸ¥æµè§ˆå™¨å¼€å‘è€…å·¥å…·**
   - Network æ ‡ç­¾æŸ¥çœ‹ WebSocket æ¶ˆæ¯
   - Console æ ‡ç­¾æŸ¥çœ‹é”™è¯¯ä¿¡æ¯

3. **æŸ¥çœ‹åç«¯æ§åˆ¶å°æ—¥å¿—**
   - ç¡®è®¤äº‹ä»¶å¤„ç†
   - æ£€æŸ¥é”™è¯¯å †æ ˆ

4. **ä½¿ç”¨ Mock æœåŠ¡è¿›è¡Œéš”ç¦»æµ‹è¯•**

### 12.3 æ—¥å¿—çº§åˆ«è®¾ç½®

**è¿è¡Œæ—¶æ›´æ”¹ï¼š**
```typescript
socket.emit("set_log_level", {
  level: "DEBUG"  // TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
})
```

**æŒä¹…åŒ–ä¿å­˜ï¼š** è®¾ç½®ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `.user_settings.yaml`

---

## é™„å½•

### å…³é”®æºæ–‡ä»¶

**æ ¸å¿ƒæ–‡ä»¶ï¼š**
- `src/anima/socketio_server.py` - Socket.IO æœåŠ¡å™¨
- `src/anima/core/events.py` - äº‹ä»¶ç±»å‹å®šä¹‰
- `src/anima/config/app.py` - åº”ç”¨é…ç½®
- `config/config.yaml` - é»˜è®¤é…ç½®

**é…ç½®ç›®å½•ï¼š**
- `config/services/llm/` - LLM æä¾›å•†é…ç½®
- `config/services/asr/` - ASR æä¾›å•†é…ç½®
- `config/services/tts/` - TTS æä¾›å•†é…ç½®
- `config/services/vad/` - VAD é…ç½®
- `config/personas/` - Persona å®šä¹‰

**æœåŠ¡å®ç°ï¼š**
- `src/anima/services/conversation/orchestrator.py` - å¯¹è¯ç¼–æ’å™¨
- `src/anima/handlers/` - äº‹ä»¶å¤„ç†å™¨
- `src/anima/eventbus/` - äº‹ä»¶æ€»çº¿

### å‚è€ƒèµ„æº

- [Socket.IO å®˜æ–¹æ–‡æ¡£](https://socket.io/docs/)
- [Faster-Whisper æ–‡æ¡£](https://github.com/SYSTRAN/faster-whisper)
- [GLM API æ–‡æ¡£](https://open.bigmodel.cn/dev/api)
- [Silero VAD æ–‡æ¡£](https://github.com/snakers4/silero-vad)

---

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** 1.0.0
**æœ€åæ›´æ–°ï¼š** 2025-02-21
