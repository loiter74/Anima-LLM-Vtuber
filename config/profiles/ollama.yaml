# Ollama 本地服务配置 - 需先安装 Ollama 并下载模型

asr:
  type: mock  # Ollama 暂不支持 ASR

tts:
  type: mock  # Ollama 暂不支持 TTS

agent:
  memory_enabled: true
  llm_config:
    type: ollama
    model: "llama3"  # llama3 / mistral / qwen2 / codellama
    base_url: "http://localhost:11434"
    temperature: 0.7  # 0.0(确定) - 2.0(随机)
    max_tokens: 2048